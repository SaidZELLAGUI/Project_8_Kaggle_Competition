{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d19afa1",
   "metadata": {},
   "source": [
    "# <font color=\"#1d479b\">**Projet 8: I'm something of a painter my self** </font>\n",
    "\n",
    "La vision par ordinateur a énormément progressé ces dernières années et les GANs sont désormais capables de mimer des objets de manière très convaincante.\n",
    "\n",
    "Dans ce challenge kaggle, le but est de générer des peinture style Monet à partir des photogaphies réelles prises par une caméra.\n",
    "\n",
    "Dataset\n",
    "\n",
    "    Monet_jpg : 300 peintures de Monet format 256x256 au format jpeg\n",
    "    monet_tfrec : 300 peintures de Monet format 256x256 au format tfrecord\n",
    "    photo_jpg : 7028 photos de taille 256x256 au format jpeg\n",
    "    photo_tfrec : 7028 photos de taille 256x256 au format tfrecord\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b2d2b0",
   "metadata": {},
   "source": [
    "## <font color=\"#1d479b\" id=\"section_1\">**1. Importation des librairies**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db952f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da8fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    # main parameters\n",
    "\n",
    "    # Root directory for dataset\n",
    "    dataroot_A = \"train_photo/photo_jpg\"\n",
    "    dataroot_B = \"train_monet/monet_jpg\"\n",
    "    \n",
    "    dataroot_test_A = \"test_photo\"\n",
    "\n",
    "    # Number of workers for dataloader\n",
    "    workers = 4\n",
    "\n",
    "    # Batch size during training\n",
    "    batch_size = 4\n",
    "\n",
    "    # Spatial size of training images. All images will be resized to this\n",
    "    #   size using a transformer.\n",
    "    image_size = 256\n",
    "\n",
    "    # Number of channels in the group A\n",
    "    input_nc = 3\n",
    "    \n",
    "    # Number of channels in the group B\n",
    "    output_nc = 3\n",
    "\n",
    "    # number of filters in the last conv layer of generator\n",
    "    ngf = 32\n",
    "\n",
    "    # number of filters in the first conv layer of discriminator\n",
    "    ndf = 16\n",
    "\n",
    "    # Number of training epochs\n",
    "    n_epochs = 20\n",
    "\n",
    "    # Learning rate for optimizers\n",
    "    lr = 0.0002\n",
    "    \n",
    "    # identity_loss coeff.\n",
    "    lambda_identity = .5\n",
    "    lambda_A = 10.0\n",
    "    lambda_B = 10.0\n",
    "\n",
    "    # Beta1 hyperparam for Adam optimizers\n",
    "    beta1 = 0.5\n",
    "\n",
    "    # Number of GPUs available. Use 0 for CPU mode.\n",
    "    ngpu = 1\n",
    "    \n",
    "    gan_mode = 'lsgan' # 'vanilla', 'wgangp'\n",
    "    \n",
    "    pool_size = 16\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "    print_freq = 1\n",
    "    save_freq = 5\n",
    "    save_dir = \"/content/drive/MyDrive/data/\"\n",
    "opt = Arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27328e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to empty up the memory in GPU\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f5a3c",
   "metadata": {},
   "source": [
    "## <font color=\"#1d479b\" id=\"section_2\">**2. Chargement des données**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06fc08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset to return pairs of images from both 2 styles\n",
    "class UnpairedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, opt):\n",
    "        self.path_A = opt.dataroot_A\n",
    "        self.path_B = opt.dataroot_B\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(opt.image_size),\n",
    "            transforms.CenterCrop(opt.image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "        \n",
    "        self.datasetA = dset.ImageFolder(root = self.path_A, transform = transform)\n",
    "        self.datasetB = dset.ImageFolder(root = self.path_B, transform = transform)\n",
    "        \n",
    "        self.size_A = len(self.datasetA)\n",
    "        self.size_B = len(self.datasetB)\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(self.size_A, self.size_B)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        A_tensor = self.datasetA[index % self.size_A][0]\n",
    "        \n",
    "        index_B = random.randint(0, self.size_B - 1)\n",
    "        B_tensor = self.datasetB[index_B][0]\n",
    "        \n",
    "        return {'A': A_tensor, 'B': B_tensor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaired_dataset = UnpairedDataset(opt)\n",
    "dataloader = torch.utils.data.DataLoader(unpaired_dataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a batch of data\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "plt.figure(figsize=(8,4), dpi=128)\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"(A): actual photos\")\n",
    "\n",
    "grid_A = vutils.make_grid(real_batch['A'], padding=2, normalize=True, nrow=4).cpu()\n",
    "plt.imshow(np.transpose(grid_A,(1,2,0)))\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "# plt.figure(figsize=(16,4), dpi=128)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"(B): Monet paintings\")\n",
    "grid_B = vutils.make_grid(real_batch['B'], padding=2, normalize=True, nrow=4).cpu()\n",
    "plt.imshow(np.transpose(grid_B,(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6793aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = dset.ImageFolder(\n",
    "    root = opt.dataroot_test_A,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(opt.image_size),\n",
    "        transforms.CenterCrop(opt.image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]))\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=4, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcce27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
